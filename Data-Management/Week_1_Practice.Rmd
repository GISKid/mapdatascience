---
title: "Session1_Exercise"
author: "Lauren"
date: "July 14th, 2020"
output: word_document
---

```{r setup, include=FALSE,fig.path = 'Figs/', dev="png",dpi=300}
knitr::opts_chunk$set(echo = TRUE)
```

# Setting up R Project

One of the first steps of every workflow should be to set up a Project within RStudio. A Project is the home for all of the files, images, reports, and code that are used in any given project. Note that when we capitalize the word Project, we’re referring to a specific setup within RStudio, while we refer to general projects that you might work on with the lowercase project.

We use Projects because they create a self-contained folder for a given analysis in R. This means that if you want to share your Project with a colleague, they will not have to reset file paths (or even know anything about file paths!) in order to re-run your analysis.

Furthermore, even if the only person you ever collaborate with is a future version of yourself, using a Project for each of your analyses will mean that you can move the Project folder around on your computer, or even move it to a new computer, and remain confident that the analysis will run in the future (at least in terms of file path structures).


Creating a Project is one of the first steps in working on an R-based data science project in RStudio. To create a Project you will need to first open RStudio.

From within RStudio, follow these steps:

    Click on File
    Select New Project
    Choose New Directory
    Click on New Project
    Enter your Project’s name in the box that says “Directory name.” We recommend choosing a Project name that helps you to remember that this is a project that involves data science in education. Avoid using spaces in your Project name, and instead separate words with hyphens or underscore characters.
    Choose where to save your Project by clicking on “Browse” next to the box labeled “Create project as a subdirectory of:” If you are just using this to learn and to test out creating a Project, consider placing it in your downloads or another temporary directory so that you remember to remove it later.
    Click “Create Project”

At this point, you should have a Project that will serve as a place to store any .R scripts that you create as you work through this text. If you’d like more practice, take a few moments to set up a couple of additional Projects by following the steps listed above. Within each Project, add and save .R scripts. Since this is just for practice, feel free to delete these Projects once you have the hang of the procedure.


# Style / Naming Conventions


# Relative Paths

    Start each program with a description of what it does.

    Then load all required packages.

    Consider what working directory you are in when sourcing a script.

    Use comments to mark off sections of code.

    Put function definitions at the top of your file, or in a separate file if there are many.

    Name and style code consistently.

    Break code into small, discrete pieces.

    Factor out common operations rather than repeating them.

    Keep all of the source files for a project in one directory and use relative paths to access them.

    Keep track of the memory used by your program.

    Always start with a clean environment instead of saving the workspace.

    Keep track of session information in your project folder.

    Have someone else review your code.

    Use version control.

##Psuedo Code

###Objectives:

1. Explore Titanics Data Set
2. Format and clean data
3. Create summaries and plots

Let's structure our document into the sections as pseudocode:

## Load Packages
## Read in Data
## Explore Titanic Data Set
## Clean and format Data
## Summarize data
## Plot data

At first it may be more general and as you move through your analysis, you might find more specific areas to explore in your data.

##Load Packages
```{r load packages}
library(tidyverse)
library(ggplot2)

```

#Load Data into R:

Here we are using the titanic data for practice and the `readr` package from the `tidyverse`

```{r read data, echo=TRUE}

titanic <- read_csv("./Raw Data/titanic.csv")

```

Be sure to read the data dictionary in the `Raw Data/` folder to get an understanding for the variable names.

Data import generally feels one of two ways:

    “Surprise me!” This is the attitude you must adopt when you first get a dataset. You are just happy to import without an error. You start to explore. You discover flaws in the data and/or the import. You address them. Lather, rinse, repeat.
    “Another day in paradise.” This is the attitude when you bring in a tidy dataset you have maniacally cleaned in one or more cleaning scripts. There should be no surprises. You should express your expectations about the data in formal assertions at the very start of these downstream scripts.

In the second case, and as the first cases progresses, you actually know a lot about how the data is / should be. My main import advice: use the arguments of your import function to get as far as you can, as fast as possible.Read the docs for the import functions and take maximum advantage of the arguments to control the import.


Get a quick summary of the data, use `?str` in the console to learn more about what each function does

```{r summary}
str(titanic)
summary(titanic)
head(titanic)
tail(titanic)
```

Take note of the **NA** values noted in summary.


Let's get a summary of who survived and who did not:

```{r survived}
titanic %>%
    count(Survived)


```

For now, we are going to remove NA values from the data where Survived is NA.

```{r titantic_na}
titanic <- titanic %>% filter(!is.na(Survived))

```


We are also going to recode this data to a "factor" type since factors contain the possible values of the data, whereas leaving this as a "numeric" column would mean that any value is possible between 0 and 1... aka 0.5, 0.8, 0.9 and we know that a person cannot be 0.5 alive.

```{r titantic_na}
titanic <- titanic %>% mutate(Survived=as.factor(Survived),
                              Sex= as.factor(Sex))

#or
# titanic$Survived=as.factor(titanic$Survived)

```

There is another way to code your columns upon import. Read the documentation for `readr` or `?read_csv`.
Column types are determined by reading the first 1000 rows of the data and estimating the type. In the cases above, it estimated that Survived was numeric after looking at 1000 rows of 1s and 0s. Since these variables are coded to mean "Survived" by 1 and "Died" by 0, we can also recode these values to make it clearer what 0 and 1 mean in plain english. We will be doing this in later sessions when we work with text.
There are some cases when you import data for an analysis that examining the first 1000 rows will not be adequate.

In these cases, if you know what columns should be factors, characters, dates, or numeric columns you can specify these directly. 
Using `col_factor, col_character, col_date(),col_double()`



```{r eval=FALSE}
titanic = read_csv("./Raw Data/titanic.csv", col_types = cols(Survived= col_factor(),
                                                          Sex= col_factor()))
#Can also do short form "f" for factor
#titanic = read_csv("./Data/titanic.csv", col_types = cols(Survived= "f",
                                                          # Sex= "f")
titanic <- titanic %>% filter(!is.na(Survived))
```


Let's plot this by age and then by sex:

```{r eda_plots}
titanic %>%
    ggplot(aes(x=Age))+
    geom_bar(position="stack")

titanic %>%
    ggplot(aes(x=Age, fill=Survived))+
    geom_bar(position = position_dodge2(preserve = "single"))


titanic %>%
    ggplot(aes(x=Age, color=Survived))+
    geom_freqpoly(binwidth = 1)


titanic %>%
    ggplot(aes(x=Sex, fill=Survived))+
    geom_bar(position="stack")

titanic %>%
    ggplot(aes(x=Sex, fill=Survived))+
    geom_bar(position = position_dodge2(preserve = "single"))




```
##Group_by

```{r group_by}

titanic %>%
    group_by(Survived, Sex)%>%
    count()

```


#Filter 

Complete the code below to filter the data by males and survivors. Then plot by age:

```{r filter}

male_survived <- titanic %>%
    filter(Sex== & Survived==)


male_survived%>%
    ggplot(aes(x=Age))+
    geom_bar()


```

Compare `male_survived` to the plot. What happened to the values in Age that are `NA` ? 
Any weird values you would not expect?



#Selection

Select only age and sex from `male_survived` and then summarize the data

```{r selection}
#This is the answer to above
male_survived <- titanic %>%
    filter(Sex=='male' & Survived==1)

male_survived<-male_survived%>%
    select(Age,Sex)
male_survived%>%
    group_by(Age,Sex)%>%
    count()


male_survived%>%
    group_by(Age,Sex)%>%
    count()%>%
    arrange(n)

male_survived%>%
    group_by(Age,Sex)%>%
    count()%>%
    arrange(desc(n))

male_survived%>%
    group_by(Age,Sex)%>%
    count()%>%
    ggplot(aes(x=Age,y=n))+
    geom_col()
```

How might we want to summarize this data even further?

##Session 2


#Mutate


Create a family size variable by combining SibSp and Parch (including the passenger themselves)

```{r mutate, echo=TRUE}

titanic <- titanic %>%
    mutate(family_size = SibSp + Parch + 1)


```


## Working with strings

Find the `title` of all passengers 


```{r title}



```

Plot the title of the passengers

```{r plot_pass}


```

Examine Cabin name. The first character is the deck. The next is the room number

```{r cabin}
titanic %>% distinct(Cabin)


```

Theres a few that have more than one Cabin and room number

```{r cabin room}

titanic %>% filter(Cabin=="C23 C25 C27")


titanic %>% filter(is.na(Cabin))
```

Investigate what could be going on with our first row. Is there a matching Ticket to find their sibling?

```{r investigate}
titanic %>% filter(str_detect(Name,"Braund"))



```



#Introduction to Markdown

Welcome ! This Markdown document is set up to export this analysis into word. Including all of the code, plots, and outputs. We can see what options are applied globally in the above "chunk", where `echo=true`. Echo will repeat the R code back to you, evaluate the code and also include the output.

As a reminder the data and materials can be found at: [https://github.com/GISKid/mapdatascience/](https://github.com/GISKid/mapdatascience/)

Above this chunk is the YAML header. You can edit this to include today's date and your name.

In Markdown there are a few ways to format text. Two `**` wrapped around a word will **bold** it, whereas this is *italics*.

We can specify different header levels with `#`. 

# header 1

## header 2

### header 3


We can also include links [Mapdatascience](www.mapdatascience.com)
and images ![Alt text](https://www.r-project.org/Rlogo.png)

For all the possibilities in R Markdown view the [cheatsheet](https://rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf).

##Structure for RMarkdown

The first chunk is the "setup" where you specify defaults. Add the following to your setup:

`fig.path = 'Figs/', dev="png",dpi=300`

When you click "knit" this will save all generated plots by their chunk name into a folder called "figs". It will also save them as a .png file and 300 dpi.

The second chunk should be where you load your data or libraries. 

The third chunk should be where you write any custom functions for easy access and editing (not covered in this webinar)

Every chunk after that can be your analysis workbook.


##Embed results into narrative

Let's create new variables to use in our markdown text:

```{r surv}

surv <- titanic %>% count(Survived) %>% filter(Survived == 1) %>% .$n
nosurv <- titanic %>% count(Survived) %>% filter(Survived == 0) %>% .$n

```

`r surv/(surv+nosurv)*100` percent of passengers survived the disaster.


